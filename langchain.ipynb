{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\onyek\\anaconda3\\envs\\myenv\\lib\\site-packages (0.3.9)\n",
      "Requirement already satisfied: openai in c:\\users\\onyek\\anaconda3\\envs\\myenv\\lib\\site-packages (1.57.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement sqlite3 (from versions: none)\n",
      "ERROR: No matching distribution found for sqlite3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 12:17:20.977 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\onyek\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import streamlit as st\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# -----------------------\n",
    "# ðŸ”¹ SETUP\n",
    "# -----------------------\n",
    "\n",
    "# Connect to SQLite Movie Database\n",
    "conn = sqlite3.connect('movie_trailers.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Initialize LangChain LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "# Setup Memory for Conversational Context\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    input_key=\"user_query\",\n",
    "    output_key=\"response\"\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# ðŸ”¹ DEFINE FUNCTIONS\n",
    "# -----------------------\n",
    "\n",
    "# âœ… **1ï¸âƒ£ Convert Natural Language to SQL**\n",
    "def generate_sql(state):\n",
    "    \"\"\"Convert user input to SQL while remembering past conversations.\"\"\"\n",
    "    query = state.user_query\n",
    "\n",
    "    # Retrieve conversation history\n",
    "    past_conversation = memory.load_memory_variables({})\n",
    "    history = past_conversation.get(\"chat_history\", \"\")\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"You are an SQL expert. Given this conversation history:\\n{history}\\n\\n\"\n",
    "        \"Convert the user's latest question into an SQL query:\\n\\n{query}\\n\\nSQL:\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a SQL assistant.\"),\n",
    "        HumanMessage(content=prompt.format(history=history, query=query))\n",
    "    ]\n",
    "    \n",
    "    sql_query = llm.invoke(messages).content.strip()  # âœ… Fixed `.invoke(messages)`\n",
    "\n",
    "    # Store query in memory\n",
    "    memory.save_context({\"user_query\": query}, {\"response\": sql_query})\n",
    "\n",
    "    return QueryState(user_query=query, sql_query=sql_query)\n",
    "\n",
    "\n",
    "# âœ… **2ï¸âƒ£ Execute SQL Query**\n",
    "def query_movie_db(state):\n",
    "    \"\"\"Executes an SQL query against the movie_trailer database.\"\"\"\n",
    "    sql_query = state.sql_query\n",
    "    try:\n",
    "        cursor.execute(sql_query)\n",
    "        results = cursor.fetchall()\n",
    "        return QueryState(user_query=state.user_query, sql_query=sql_query, db_results=results if results else \"No results found.\")\n",
    "    except Exception as e:\n",
    "        return QueryState(user_query=state.user_query, sql_query=sql_query, db_results=f\"Error executing query: {str(e)}\")\n",
    "\n",
    "\n",
    "# âœ… **3ï¸âƒ£ Format Results**\n",
    "def format_results(state):\n",
    "    \"\"\"Format query results into natural language.\"\"\"\n",
    "    results = state.db_results\n",
    "    return QueryState(user_query=state.user_query, sql_query=state.sql_query, db_results=f\"Results:\\n{results}\" if results else \"No relevant data found.\")\n",
    "\n",
    "\n",
    "# âœ… **4ï¸âƒ£ General Movie Knowledge (LLM)**\n",
    "def answer_general_movie_question(question: str) -> str:\n",
    "    \"\"\"Uses GPT to answer general movie-related questions.\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a movie expert. Answer questions about movies, actors, and awards.\"),\n",
    "        HumanMessage(content=question)\n",
    "    ]\n",
    "    response = llm.invoke(messages).content  # âœ… Fixed `.invoke(messages)`\n",
    "    return response\n",
    "\n",
    "# -----------------------\n",
    "# ðŸ”¹ SET UP LangGraph PIPELINE\n",
    "# -----------------------\n",
    "@dataclass\n",
    "class QueryState:\n",
    "    user_query: str = \"\"\n",
    "    sql_query: str = \"\"\n",
    "    db_results: str = \"\"\n",
    "\n",
    "graph = StateGraph(QueryState)\n",
    "graph.add_node(\"generate_sql\", generate_sql)\n",
    "graph.add_node(\"execute_sql\", query_movie_db)\n",
    "graph.add_node(\"format_response\", format_results)\n",
    "\n",
    "graph.set_entry_point(\"generate_sql\")\n",
    "graph.add_edge(\"generate_sql\", \"execute_sql\")\n",
    "graph.add_edge(\"execute_sql\", \"format_response\")\n",
    "graph.add_edge(\"format_response\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# -----------------------\n",
    "# ðŸ”¹ DEFINE LANGCHAIN AGENT\n",
    "# -----------------------\n",
    "\n",
    "# âœ… **Database Query Tool**\n",
    "db_tool = Tool(\n",
    "    name=\"MovieDB\",\n",
    "    func=lambda query: app.invoke(QueryState(user_query=query)).db_results,  # âœ… Fixed incorrect lambda return\n",
    "    description=\"Queries the movie_trailer database and returns movie-related information.\"\n",
    ")\n",
    "\n",
    "# âœ… **General Movie Knowledge Tool**\n",
    "llm_tool = Tool(\n",
    "    name=\"MovieKnowledge\",\n",
    "    func=answer_general_movie_question,\n",
    "    description=\"Answers general movie-related questions, such as movie plots, actor details, and award history.\"\n",
    ")\n",
    "\n",
    "# âœ… **Initialize LangChain Agent**\n",
    "tools = [db_tool, llm_tool]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=False  # âœ… Reduced verbosity for better performance\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# ðŸ”¹ STREAMLIT UI\n",
    "# -----------------------\n",
    "\n",
    "# âœ… **Ensure session state for conversation history**\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = \"\"\n",
    "\n",
    "st.title(\"ðŸŽ¬ Movie Insights Chatbot\")\n",
    "\n",
    "# User Input\n",
    "user_query = st.text_area(\"Ask about movies:\", \"\")\n",
    "\n",
    "# Submit Button\n",
    "if st.button(\"Get Insights\"):\n",
    "    if user_query.strip():\n",
    "        # Run the AI pipeline\n",
    "        response = agent.run(user_query)\n",
    "\n",
    "        # âœ… **Store conversation history properly**\n",
    "        st.session_state.chat_history += f\"User: {user_query}\\nAgent: {response}\\n\"\n",
    "\n",
    "        # âœ… **Show chat history**\n",
    "        st.subheader(\"ðŸ“œ Chat History\")\n",
    "        st.text(st.session_state.chat_history)\n",
    "\n",
    "        # âœ… **Show insights**\n",
    "        st.subheader(\"ðŸ“Š Insights\")\n",
    "        st.write(response)\n",
    "        \n",
    "    else:\n",
    "        st.warning(\"Please enter a query.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
